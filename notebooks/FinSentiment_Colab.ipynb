{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#  FinSentiment: An谩lisis de Sentimiento Financiero en la Nube\n",
                "\n",
                "Este notebook integra todo el pipeline de FinSentiment para ejecutarse en Google Colab.\n",
                "Aprovechamos la velocidad de descarga y procesamiento de la nube para evitar limitaciones de hardware local.\n",
                "\n",
                "### Pasos:\n",
                "1. Ejecutar instalaci贸n de dependencias.\n",
                "2. Ejecutar las celdas de definici贸n de clases.\n",
                "3. Ejecutar el an谩lisis final con el ticker de tu elecci贸n."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 1. Instalaci贸n de Dependencias\n",
                "# Instalamos librer铆as necesarias en el entorno de Colab\n",
                "!pip install sec-edgar-downloader transformers torch pandas numpy matplotlib seaborn beautifulsoup4\n",
                "!mkdir -p data/raw data/processed reports/figures"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 2. Definici贸n de M贸dulos (Ingesta, Limpieza, Modelo, Visualizaci贸n)\n",
                "\n",
                "import os\n",
                "import re\n",
                "import glob\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime\n",
                "from bs4 import BeautifulSoup\n",
                "from sec_edgar_downloader import Downloader\n",
                "from transformers import BertTokenizer, BertForSequenceClassification\n",
                "\n",
                "# --- MDULO 1: INGESTA ---\n",
                "class SECLoader:\n",
                "    def __init__(self, data_dir=\"data\", email=\"usuario@example.com\", company=\"Personal Research\"):\n",
                "        self.data_dir = data_dir\n",
                "        os.makedirs(os.path.join(data_dir, \"raw\"), exist_ok=True)\n",
                "        os.makedirs(os.path.join(data_dir, \"processed\"), exist_ok=True)\n",
                "        self.downloader = Downloader(company, email, os.path.join(data_dir, \"raw\"))\n",
                "\n",
                "    def download_filings(self, ticker: str, amount: int = 1):\n",
                "        print(f\"[>] Descargando reportes para {ticker}...\")\n",
                "        try:\n",
                "            self.downloader.get(\"10-K\", ticker, limit=amount)\n",
                "            self.downloader.get(\"10-Q\", ticker, limit=amount)\n",
                "            print(\"[+] Descarga completa.\")\n",
                "        except Exception as e:\n",
                "            print(f\"[!] Error en descarga: {e}\")\n",
                "\n",
                "    def extract_mda(self, html_content: str) -> str:\n",
                "        soup = BeautifulSoup(html_content, 'html.parser')\n",
                "        text = soup.get_text(separator='\\n')\n",
                "        # Heur铆stica simple para MD&A (Item 7)\n",
                "        mda_start_patterns = [\n",
                "            r'Item\\s+7\\.\\s+Management\\'s\\s+Discussion',\n",
                "            r'MANAGEMENT\\'S\\s+DISCUSSION\\s+AND\\s+ANALYSIS'\n",
                "        ]\n",
                "        mda_end_patterns = [\n",
                "            r'Item\\s+7A\\.\\s+Quantitative',\n",
                "            r'Item\\s+8\\.\\s+Financial'\n",
                "        ]\n",
                "        \n",
                "        start_idx = -1\n",
                "        for p in mda_start_patterns:\n",
                "            match = re.search(p, text, re.IGNORECASE)\n",
                "            if match:\n",
                "                start_idx = match.start()\n",
                "                break\n",
                "        \n",
                "        if start_idx == -1: return \"\"\n",
                "        \n",
                "        end_idx = -1\n",
                "        for p in mda_end_patterns:\n",
                "            match = re.search(p, text[start_idx:], re.IGNORECASE)\n",
                "            if match:\n",
                "                end_idx = start_idx + match.start()\n",
                "                break\n",
                "        \n",
                "        if end_idx != -1:\n",
                "            return text[start_idx:end_idx]\n",
                "        return text[start_idx:start_idx+100000] # Fallback\n",
                "\n",
                "    def process_local_filings(self, ticker: str):\n",
                "        raw_path = os.path.join(self.data_dir, \"raw\", \"sec-edgar-filings\", ticker)\n",
                "        print(f\"[*] Procesando archivos locales para {ticker}...\")\n",
                "        \n",
                "        processed_count = 0\n",
                "        for root, dirs, files in os.walk(raw_path):\n",
                "            for file in files:\n",
                "                if file.endswith(\".html\") or file.endswith(\".txt\"):\n",
                "                    full_path = os.path.join(root, file)\n",
                "                    try:\n",
                "                        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
                "                            content = f.read()\n",
                "                        \n",
                "                        mda = self.extract_mda(content)\n",
                "                        if len(mda) > 1000:\n",
                "                            doc_type = \"10-K\" if \"10-K\" in root else \"10-Q\"\n",
                "                            accession = os.path.basename(os.path.dirname(full_path))\n",
                "                            save_path = os.path.join(self.data_dir, \"processed\", f\"{ticker}_{doc_type}_{accession}_MDA.txt\")\n",
                "                            with open(save_path, 'w', encoding='utf-8') as f_out:\n",
                "                                f_out.write(mda)\n",
                "                            processed_count += 1\n",
                "                    except Exception as e:\n",
                "                        pass\n",
                "        print(f\"[+] Procesados {processed_count} reportes.\")\n",
                "\n",
                "# --- MDULO 2: PREPROCESAMIENTO ---\n",
                "class TextPreprocessor:\n",
                "    def clean_text(self, text):\n",
                "        text = re.sub(r'\\s+', ' ', text)\n",
                "        text = \"\".join(ch for ch in text if ch.isprintable())\n",
                "        return text.strip()\n",
                "    \n",
                "    def split_sentences(self, text):\n",
                "        sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])', text)\n",
                "        return [s.strip() for s in sentences if len(s.split()) >= 4]\n",
                "\n",
                "# --- MDULO 3: MODELO FINBERT ---\n",
                "class FinBertModel:\n",
                "    def __init__(self):\n",
                "        print(\"[*] Cargando modelo FinBERT (esto es r谩pido en Colab)...\\n\")\n",
                "        self.model_name = \"ProsusAI/finbert\"\n",
                "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
                "        self.model = BertForSequenceClassification.from_pretrained(self.model_name)\n",
                "        # Mover a GPU si est谩 disponible\n",
                "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "        self.model.to(self.device)\n",
                "        print(f\"[+] Modelo cargado en: {self.device}\")\n",
                "        self.labels = {0: 'positive', 1: 'negative', 2: 'neutral'}\n",
                "\n",
                "    def predict_batch(self, sentences):\n",
                "        if not sentences: return pd.DataFrame()\n",
                "        inputs = self.tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
                "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            outputs = self.model(**inputs)\n",
                "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
                "        \n",
                "        probs_np = probs.cpu().numpy()\n",
                "        results = []\n",
                "        for i, s in enumerate(sentences):\n",
                "            max_idx = np.argmax(probs_np[i])\n",
                "            results.append({\n",
                "                \"sentence\": s,\n",
                "                \"positive\": probs_np[i][0],\n",
                "                \"negative\": probs_np[i][1],\n",
                "                \"neutral\": probs_np[i][2],\n",
                "                \"sentiment_label\": self.labels[max_idx]\n",
                "            })\n",
                "        return pd.DataFrame(results)\n",
                "\n",
                "# --- MDULO 4: VISUALIZACIN ---\n",
                "def plot_trend(df, ticker):\n",
                "    if df.empty: return\n",
                "    df = df.sort_values('date')\n",
                "    df['ma'] = df['sentiment_score'].rolling(window=3, min_periods=1).mean()\n",
                "    \n",
                "    plt.figure(figsize=(12, 6))\n",
                "    plt.plot(df['date'], df['sentiment_score'], 'o-', label='Sentiment Score', color='#2E86AB')\n",
                "    plt.plot(df['date'], df['ma'], '--', label='Media M贸vil', color='red')\n",
                "    plt.axhline(0, color='gray', alpha=0.5)\n",
                "    plt.title(f'Evoluci贸n del Sentimiento: {ticker}')\n",
                "    plt.legend()\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title 3. EJECUTAR ANLISIS\n",
                "TICKER = \"ADBE\" # @param {type:\"string\"}\n",
                "NUM_REPORTS = 2 # @param {type:\"integer\"}\n",
                "\n",
                "# 1. Ingesta\n",
                "loader = SECLoader()\n",
                "loader.download_filings(TICKER, amount=NUM_REPORTS)\n",
                "loader.process_local_filings(TICKER)\n",
                "\n",
                "# 2. Preprocesamiento y An谩lisis\n",
                "preprocessor = TextPreprocessor()\n",
                "model = FinBertModel()\n",
                "\n",
                "processed_dir = \"data/processed\"\n",
                "files = [f for f in os.listdir(processed_dir) if TICKER in f]\n",
                "\n",
                "results_agg = []\n",
                "\n",
                "for file in files:\n",
                "    print(f\"\\nAnalizando: {file}\")\n",
                "    with open(os.path.join(processed_dir, file), 'r') as f:\n",
                "        text = f.read()\n",
                "    \n",
                "    sentences = preprocessor.split_sentences(preprocessor.clean_text(text))\n",
                "    print(f\" - Oraciones: {len(sentences)}\")\n",
                "    \n",
                "    # Batch processing simple (de 10 en 10 para no saturar RAM de Colab si es muy grande)\n",
                "    all_preds = []\n",
                "    chunk_size = 16\n",
                "    for i in range(0, len(sentences), chunk_size):\n",
                "        batch = sentences[i:i+chunk_size]\n",
                "        preds = model.predict_batch(batch)\n",
                "        all_preds.append(preds)\n",
                "    \n",
                "    if all_preds:\n",
                "        df_file = pd.concat(all_preds)\n",
                "        net_score = df_file['positive'].mean() - df_file['negative'].mean()\n",
                "        results_agg.append({\n",
                "            'date': datetime.now(), # Proxy, en real usar铆amos fecha del fila\n",
                "            'sentiment_score': net_score\n",
                "        })\n",
                "        print(f\" - Score Neto: {net_score:.3f}\")\n",
                "\n",
                "# 3. Visualizaci贸n\n",
                "if results_agg:\n",
                "    df_final = pd.DataFrame(results_agg)\n",
                "    # Simular fechas para demo si todas son 'hoy'\n",
                "    df_final['date'] = pd.date_range(end=datetime.now(), periods=len(df_final), freq='3M')\n",
                "    \n",
                "    plot_trend(df_final, TICKER)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}