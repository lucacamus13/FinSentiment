{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 游 FinSentiment 3.0: Sector Screener (Batch Edition)\n",
        "\n",
        "Versi칩n escalable para analizar m칰ltiples empresas del sector tecnol칩gico de forma secuencial y comparativa.\n",
        "\n",
        "### Nuevas Caracter칤sticas (Fase 7):\n",
        "1. **Batch Processing**: An치lisis autom치tico de ['META', 'AAPL', 'MSFT', 'GOOGL', 'AMZN'].\n",
        "2. **Robustez**: Manejo de errores encapsulado (si falla uno, sigue el siguiente).\n",
        "3. **Screener Visual**: Ranking de sentimiento (Z-Score) para comparar empresas.\n",
        "4. **Core v2.1**: Filtros legales y normalizaci칩n estad칤stica ya integrados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 1. Instalaci칩n de Dependencias\n",
        "!pip install sec-edgar-downloader transformers torch pandas numpy matplotlib seaborn beautifulsoup4 yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 2. Definici칩n del Motor (Core Engine v2.1)\n",
        "\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "from collections import Counter\n",
        "from datetime import datetime, timedelta\n",
        "from bs4 import BeautifulSoup\n",
        "from sec_edgar_downloader import Downloader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Configurar estilos\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = [14, 7]\n",
        "\n",
        "# --- M칍DULO 1: INGESTA ---\n",
        "class SECLoader:\n",
        "    def __init__(self, data_dir=\"data\", email=\"research@example.com\", company=\"Personal Research\"):\n",
        "        self.data_dir = data_dir\n",
        "        os.makedirs(os.path.join(data_dir, \"raw\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(data_dir, \"processed\"), exist_ok=True)\n",
        "        self.downloader = Downloader(company, email, os.path.join(data_dir, \"raw\"))\n",
        "\n",
        "    def download_filings(self, ticker: str, amount: int = 1):\n",
        "        path = os.path.join(self.data_dir, \"raw\", \"sec-edgar-filings\", ticker)\n",
        "        # En batch mode, a veces conviene forzar descarga si amount es bajo\n",
        "        print(f\"[>] ({ticker}) Iniciando descarga de 칰ltimo reporte...\")\n",
        "        try:\n",
        "            self.downloader.get(\"10-K\", ticker, limit=amount)\n",
        "        except Exception as e:\n",
        "            print(f\"[!] Error en descarga {ticker}: {e}\")\n",
        "\n",
        "    def extract_date(self, content: str) -> str:\n",
        "        patterns = [\n",
        "            r'FILED AS OF DATE:\\s+(\\d{8})',\n",
        "            r'CONFORMED PERIOD OF REPORT:\\s+(\\d{8})'\n",
        "        ]\n",
        "        for p in patterns:\n",
        "            match = re.search(p, content)\n",
        "            if match:\n",
        "                date_str = match.group(1)\n",
        "                return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
        "        return None\n",
        "\n",
        "    def extract_mda(self, html_content: str) -> str:\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        text = soup.get_text(separator='\\n')\n",
        "        patterns = [r'Item\\s+7\\.\\s+Management', r\"Management's\\s+Discussion\", r'Item\\s+7\\.']\n",
        "        start_idx = -1\n",
        "        for p in patterns:\n",
        "            match = re.search(p, text, re.IGNORECASE)\n",
        "            if match: start_idx = match.start(); break\n",
        "        if start_idx == -1: return text[:50000]\n",
        "        return text[start_idx:start_idx+30000]\n",
        "\n",
        "    def process_filings(self, ticker: str):\n",
        "        raw_path = os.path.join(self.data_dir, \"raw\", \"sec-edgar-filings\", ticker)\n",
        "        processed_data = []\n",
        "        for root, _, files in os.walk(raw_path):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(\".txt\") and \"primary\" not in file:\n",
        "                    try:\n",
        "                        with open(os.path.join(root, file), 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                            content = f.read()\n",
        "                        mda = self.extract_mda(content)\n",
        "                        date = self.extract_date(content)\n",
        "                        if len(mda) > 500:\n",
        "                            processed_data.append({'text': mda, 'date': date, 'accession': file})\n",
        "                    except: pass\n",
        "        # Ordenar por fecha reciente\n",
        "        return sorted(processed_data, key=lambda x: x.get('date', '1900'), reverse=True)\n",
        "\n",
        "# --- M칍DULO 2 NOISE FILTER ---\n",
        "class TextPreprocessor:\n",
        "    def clean_text(self, text):\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        return \"\".join(ch for ch in text if ch.isprintable()).strip()\n",
        "    \n",
        "    def is_legal_noise(self, sentence: str) -> bool:\n",
        "        legal_keywords = [\n",
        "            'forward-looking', 'safe harbor', 'uncertainty', 'may differ', \n",
        "            'subject to error', 'actual results', 'factors that could cause',\n",
        "            'statements regarding', 'cautionary note', 'risk factors', \n",
        "            'include but are not limited to', 'assumptions'\n",
        "        ]\n",
        "        return any(kw in sentence.lower() for kw in legal_keywords)\n",
        "\n",
        "    def split_sentences(self, text):\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])', text)\n",
        "        valid_sentences = []\n",
        "        for s in sentences:\n",
        "            s = s.strip()\n",
        "            if len(s) > 20 and len(s.split()) >= 4:\n",
        "                if not self.is_legal_noise(s):\n",
        "                    valid_sentences.append(s)\n",
        "        return valid_sentences\n",
        "\n",
        "# --- M칍DULO 3 FINBERT ---\n",
        "class FinBertModel:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "        self.model = BertForSequenceClassification.from_pretrained(\"ProsusAI/finbert\").to(self.device)\n",
        "        self.labels = {0: 'positive', 1: 'negative', 2: 'neutral'}\n",
        "\n",
        "    def predict(self, sentences):\n",
        "        if not sentences: return pd.DataFrame()\n",
        "        batch_size = 32\n",
        "        results = []\n",
        "        for i in range(0, len(sentences), batch_size):\n",
        "            batch = sentences[i:i+batch_size]\n",
        "            inputs = self.tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                probs = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "            for j, s in enumerate(batch):\n",
        "                results.append({\n",
        "                    \"sentence\": s,\n",
        "                    \"pos_val\": probs[j][0],\n",
        "                    \"neg_val\": probs[j][1]\n",
        "                })\n",
        "        return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 3. Ejecuci칩n Batch (Multi-Ticker)\n",
        "\n",
        "# Inicializar Modelos fuera del loop para eficiencia\n",
        "print(\"[*] Inicializando Motor NLP...\")\n",
        "loader = SECLoader()\n",
        "model = FinBertModel()\n",
        "prep = TextPreprocessor()\n",
        "\n",
        "def analyze_ticker(ticker_symbol):\n",
        "    \"\"\"Funci칩n Maestra: Procesa una empresa de principio a fin.\"\"\"\n",
        "    print(f\"\\n--- Procesando {ticker_symbol} ---\")\n",
        "    try:\n",
        "        # 1. Download\n",
        "        loader.download_filings(ticker_symbol, amount=1)\n",
        "        \n",
        "        # 2. Process\n",
        "        docs = loader.process_filings(ticker_symbol)\n",
        "        if not docs:\n",
        "            print(f\"[!] No se encontraron reportes legibles para {ticker_symbol}\")\n",
        "            return None\n",
        "            \n",
        "        latest_doc = docs[0] # Tomamos el m치s reciente\n",
        "        report_date = latest_doc.get('date', 'Unknown')\n",
        "        print(f\"[>] Analizando reporte del {report_date}...\")\n",
        "        \n",
        "        # 3. Clean & Predict\n",
        "        sentences = prep.split_sentences(prep.clean_text(latest_doc['text']))\n",
        "        df = model.predict(sentences)\n",
        "        \n",
        "        if df.empty:\n",
        "            return None\n",
        "            \n",
        "        # 4. Calculate Metrics\n",
        "        net_score = df['pos_val'].mean() - df['neg_val'].mean()\n",
        "        \n",
        "        # Z-Score muy aproximado (usando una desviaci칩n est치ndar te칩rica del sector si no hay historial)\n",
        "        # Para ser justos en una comparativa transversal, usamos el Score Neto directo o un Z-Score vs sus oraciones.\n",
        "        # Aqu칤 calcularemos Z-Score interno de las oraciones para ver consistencia.\n",
        "        # PERO para el Screener Visual, el usuario pidi칩 Z-Score.\n",
        "        # Como es un solo punto de dato por empresa, es dif칤cil calcular Z-Score hist칩rico en una sola corrida r치pida.\n",
        "        # Simularemos Z-Score normalizando contra una media 'neutral' (0).\n",
        "        \n",
        "        return {\n",
        "            'ticker': ticker_symbol,\n",
        "            'date': report_date,\n",
        "            'net_score': net_score\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Fallo cr칤tico en {ticker_symbol}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- BUCLE PRINCIPAL ---\n",
        "TICKERS = ['META', 'AAPL', 'MSFT', 'GOOGL', 'AMZN']\n",
        "sector_results = []\n",
        "\n",
        "for t in TICKERS:\n",
        "    res = analyze_ticker(t)\n",
        "    if res:\n",
        "        sector_results.append(res)\n",
        "\n",
        "# Construir DataFrame\n",
        "df_sector = pd.DataFrame(sector_results)\n",
        "\n",
        "if not df_sector.empty:\n",
        "    # Calcular Z-Score relativo al GRUPO (Sectorial)\n",
        "    # Esto nos dice qui칠n est치 mejor/peor que sus pares HOY.\n",
        "    sector_mean = df_sector['net_score'].mean()\n",
        "    sector_std = df_sector['net_score'].std()\n",
        "    if sector_std == 0: sector_std = 1\n",
        "    \n",
        "    df_sector['z_score'] = (df_sector['net_score'] - sector_mean) / sector_std\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\" SECTOR SCREENER RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    display(df_sector.sort_values('z_score', ascending=False))\n",
        "    \n",
        "    # --- VISUALIZACI칍N COMPARATIVA ---\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    # Colores divergentes: Verde para positivo, Rojo para negativo\n",
        "    colors = ['#2ecc71' if x >= 0 else '#e74c3c' for x in df_sector['z_score']]\n",
        "    \n",
        "    sns.barplot(x='z_score', y='ticker', data=df_sector.sort_values('z_score', ascending=False), palette=colors)\n",
        "    \n",
        "    plt.title('Market Sentiment Screener: Tech Sector (Z-Score Relativo)', fontsize=15, fontweight='bold')\n",
        "    plt.xlabel('Z-Score (Desviaci칩n respecto al promedio del grupo)', fontsize=12)\n",
        "    plt.ylabel('Ticker', fontsize=12)\n",
        "    plt.axvline(0, color='black', linestyle='--', alpha=0.3)\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"[!] No se obtuvieron resultados v치lidos para generar el gr치fico.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}